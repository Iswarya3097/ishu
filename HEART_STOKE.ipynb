{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VALIDATION AND DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING A LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIEVE THE DATASET\n",
    "df=pd.read_csv(\"heart_stoke.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIEVE TOP OF THE FIVE ELEMENTS\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER OF ROWS AND COLUMNS\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING A NULL VALUES\n",
    "df1=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIEVE TOP OF THE FIVE ELEMENTS\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER OF ROWS AND COLUMNS IN DATASET\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIEVE A COLUMNS NAMES\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUMMARIES THE DATASET\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING THE DATASET AND INFORMATION ABOUT DATASET\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING FOR DUPLICATED DATA\n",
    "df1.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING FOR SUM OF DUPLICATED DATA VALUE\n",
    "sum(df1.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING SUM OF MISSING VALUES\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.work_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Residence_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.avg_glucose_level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.bmi.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.smoking_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.hypertension.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO VALIDATE A AGE OF PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum value of Age of patient is:\", df1.age.min())\n",
    "print(\"Maximum value of Age of patient is:\", df1.age.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age of patient ranges :\", sorted(df1['age'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df1['avg_glucose_level']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df1['smoking_status']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEFORE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFTER PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
    "       'smoking_status']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df1[i] = le.fit_transform(df1[i]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df2.age,df2.smoking_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram Plot of Age distribution\n",
    "df2['age'].hist(figsize=(10,6), color='blue', alpha=0.7)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('No of Patients')\n",
    "plt.title('age of distribution of patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propagation by variable\n",
    "def Prop(df2, variable):\n",
    "    dataframe_pie = df2[variable].value_counts()\n",
    "    ax = dataframe_pie.plot.pie(figsize=(20,20), autopct='%1.2f%%', fontsize = 20)\n",
    "    ax.set_title(variable + ' \\n', fontsize = 20)\n",
    "    return np.round(dataframe_pie/df2.shape[0]*100,2)\n",
    "Prop(df2, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propagation by variable\n",
    "def Prop(df2, variable):\n",
    "    dataframe_pie = df2[variable].value_counts()\n",
    "    ax = dataframe_pie.plot.pie(figsize=(20,20), autopct='%1.2f%%', fontsize = 20)\n",
    "    ax.set_title(variable + ' \\n', fontsize = 15)\n",
    "    return np.round(dataframe_pie/df2.shape[0]*100,2)\n",
    "\n",
    "Prop(df2, 'work_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap plot diagram\n",
    "fig, ax = plt.subplots(figsize=(25,20))\n",
    "sns.heatmap(df2.corr(), ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df2[\"gender\"]\n",
    "ag = df2[\"age\"]\n",
    "hy = df2[\"hypertension\"]\n",
    "hd = df2[\"heart_disease\"]\n",
    "mr = df2[\"ever_married\"]\n",
    "wt = df2[\"work_type\"]\n",
    "rt = df2[\"Residence_type\"]\n",
    "avgl = df2[\"avg_glucose_level\"]\n",
    "bm = df2[\"bmi\"]\n",
    "sm = df2[\"smoking_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ag, g, color='g')\n",
    "plt.xlabel('Patient Age Details')\n",
    "plt.ylabel('Gender Details')\n",
    "plt.title('Patient Age Details by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
    "       'smoking_status', 'stroke']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df2[i] = le.fit_transform(df2[i]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing, split test and dataset, split response variable\n",
    "X = df2.drop(labels='stroke', axis=1)\n",
    "#Response variable\n",
    "y = df2.loc[:,'stroke']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll use a test size of 30%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "print(\"Number of training dataset: \", len(X_train))\n",
    "print(\"Number of test dataset: \", len(X_test))\n",
    "print(\"Total number of dataset: \", len(X_train)+len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qul_No_qul_bar_plot(df2, bygroup):\n",
    "    dataframe_by_Group = pd.crosstab(df[bygroup], columns=df[\"stroke\"], normalize = 'index')\n",
    "    dataframe_by_Group = np.round((dataframe_by_Group * 100), decimals=2)\n",
    "    ax = dataframe_by_Group.plot.bar(figsize=(20,10));\n",
    "    vals = ax.get_yticks()\n",
    "    ax.set_yticklabels(['{:3.0f}%'.format(x) for x in vals]);\n",
    "    ax.set_xticklabels(dataframe_by_Group.index,rotation = 0, fontsize = 15);\n",
    "    ax.set_title('Stroke having or not by given attributes (%) (by ' + dataframe_by_Group.index.name + ')\\n', fontsize = 20)\n",
    "    ax.set_xlabel(dataframe_by_Group.index.name, fontsize = 12)\n",
    "    ax.set_ylabel('(%)', fontsize = 15)\n",
    "    ax.legend(loc = 'upper left',bbox_to_anchor=(1.0,1.0), fontsize= 12)\n",
    "    rects = ax.patches\n",
    "\n",
    "    # Add Data Labels\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, \n",
    "                height + 2, \n",
    "                str(height)+'%', \n",
    "                ha='center', \n",
    "                va='bottom',\n",
    "                fontsize = 12)\n",
    "    return dataframe_by_Group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qul_No_qul_bar_plot(df, 'work_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE MEASURE OF LOGISTIC REGRESSION AND DECISION TREE ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df2 \n",
    "#We'll use a test size of 30%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for our convienient we delete X,y variable for differentiate confusion\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent view warnings\n",
    "X_train.is_copy = False\n",
    "X_test.is_copy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log= LogisticRegression()\n",
    "\n",
    "log.fit(X_train,y_train)\n",
    "\n",
    "predict = log.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Logistic Regression Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predict))\n",
    "x = (accuracy_score(y_test,predict)*100)\n",
    "\n",
    "print('Accuracy result of Logistic Regression is:', x)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predict)\n",
    "print('Confusion Matrix result of Logistic Regression is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "predictDT = dtree.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Decision Tree Classifier Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictDT))\n",
    "x = (accuracy_score(y_test,predictDT)*100)\n",
    "\n",
    "print('Accuracy result of Decision Tree Classifier is', x)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predictDT)\n",
    "print('Confusion Matrix result of Decision Tree Classifier is:\\n', confusion_matrix(y_test,predictDT))\n",
    "print(\"\")\n",
    "\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm2[0][0]\n",
    "FN = cm2[1][0]\n",
    "TP = cm2[1][1]\n",
    "FP = cm2[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE MEASURE OF RANDOM FOREST AND SUPPORT VECTOR MACHINE ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "predictR1 = rfc.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Random Forest Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR1))\n",
    "x = (accuracy_score(y_test,predictR1)*100)\n",
    "\n",
    "print('Accuracy result of Random Forest is:', x)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR1)\n",
    "print('Confusion Matrix result of Random Forest is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "s = SVC()\n",
    "\n",
    "s.fit(X_train,y_train)\n",
    "\n",
    "predicts = s.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Support Vector Machines Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predicts))\n",
    "x = (accuracy_score(y_test,predicts)*100)\n",
    "\n",
    "print('Accuracy result of Support Vector Machines is:', x)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predicts)\n",
    "print('Confusion Matrix result of Support Vector Machines is:\\n',cm2)\n",
    "print(\"\")\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm2[0][0]\n",
    "FN = cm2[1][0]\n",
    "TP = cm2[1][1]\n",
    "FP = cm2[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
